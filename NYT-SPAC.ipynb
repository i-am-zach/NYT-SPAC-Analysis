{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Law School: Analyzing Financial Memes Using Data Science\n",
    "\n",
    "By Zach Lefkovitz (in coordination with Graham Ambrose, Stanford Law School).\n",
    "\n",
    "09/12/2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Special Purpose Acquisition Companies\n",
    "\n",
    "Special Purpose Acquisition Companies (SPACs) are companies created solely for the purpose of raising capital through an initial public offering (IPO) with the intention of acquiring an existing private company and taking it public. SPACs are also known as \"blank check\" companies, as they have no operations or business activities at the time of their IPO. SPACs are highly criticized for over selling their companies assets and being a method of enriching insiders.\n",
    "\n",
    "## An Opportunity is Presented\n",
    "\n",
    "![Stanford Law School](assets/sls-social-default.jpg)\n",
    "\n",
    "Graham Ambrose is a law student at Stanford Law School and the older brother of my good high school friend, Zac. This winter break, Zac reached out to me because Graham was looking for a computer scientist to help assist him with a data science project for his research on SPACs. Not wanting to pass on an opportunity to get my name in law review, I accepted the opportunity and began to message Graham.\n",
    "\n",
    "## Professor Klausner\n",
    "\n",
    "Graham does research for [Professor Michael Klausner](https://law.stanford.edu/directory/michael-klausner/). Klasuner teachers and writer for the Stanford Nancy and Charles Munger School of Business and Stanford Law School. His special research area is in Banking and Financial Institutions, Business & Corporate Law, and Capital Markets. His 2020 publication, *A Sober Look at SPACs,* has been cited by the SEC in proposing regulation to the industry and he is currently suing three SPACs in Delaware Court.\n",
    "\n",
    "## Research Purpose\n",
    "\n",
    "![Wall Street Bets](assets/WallStreetBets.png)\n",
    "\n",
    "In his research, Graham wanted to explore when and why SPACs became so popular. Through platforms like Twitter and Reddit's r/WallStreetBets, SPACs became a financial meme. Using data science, Graham wanted to know exactly when SPACs started becoming popular. SPACs have been financial tools since the 90s but he hypothesizes there's been a sharp increase in the use of SPACs in public knowledge starting in 2020. \n",
    "\n",
    "## Limitations\n",
    "\n",
    "![Translation of SPAC](assets/spac-translation.png)\n",
    "\n",
    "Since Twitter was a popular platform for the promoting and growing of SPACs as a financial meme, it would seem intuitive to scrape twitter content that contain the word \"SPAC\" for our data. However the word \"spac\" means \"to sleep\" in Polish so it would make analysis more complicated. While it would be possible to use an algorithm to determine the tweet was in English or Polish to filter the data, instead we decided to use New York Times articles as a measure of the prevalence of SPACs in public discourse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Collection\n",
    "\n",
    "To collect the data, we are going to use the New York Times API. This API can be found by Googling \"New York Times API\" are going to the URL https://developer.nytimes.com/.\n",
    "\n",
    "## Creating an App\n",
    "\n",
    "After creating a developer account with the New York Times, we need to create an app in order to obtain our API key. Under the accounts section on the top right, click on \"apps\" > Create New App. I created a new app called \"NYT SPAC Analysis\" and enabled the article search API.\n",
    "\n",
    "![Create New App](assets/nyt/new-app.png)\n",
    "\n",
    "Once the app is created, I copied my public and secret key and saved it to a .env file in my project's root directory. My .env file follows this format:\n",
    "```\n",
    "NYT_API_KEY=<YOUR API KEY>\n",
    "NYT_SECRET_KEY=<YOUR SECRET KEY>\n",
    "```\n",
    "\n",
    "In the later parts of the project, I'll load the environment variables from that .env file into my python script.\n",
    "\n",
    "## Exploring the Article Search API\n",
    "\n",
    "The New York Times provides documentation for all their API endpoints. For the purpose of this project, we are going to use the article search API. The article search API allows NYT article look ups by keywords. The documentation can be found here: https://developer.nytimes.com/docs/articlesearch-product/1/overview.\n",
    "\n",
    "From the NYT Article Search API documentation, here is an example API url:\n",
    "\n",
    "```https://api.nytimes.com/svc/search/v2/articlesearch.json?q=election&api-key=yourkey```\n",
    "\n",
    "Breaking down the url into its components:\n",
    "* `https://api.nytimes.com/svc/search/v2/articlesearch.json`: The base url for the article search API\n",
    "* `?q=election`: Query for the keyword \"election\" in NYT articles\n",
    "* `api-key=yourkey`: Dedicated keyword to provide your API key to authenticate the API\n",
    "\n",
    "Some other useful query parameters useful for us:\n",
    "* `sort` = \"newest\" | \"oldest\" | \"relevance\": Sort the API results by chronologically or by relevance. Sorting chronologically will be nice for graphing the data in time series.\n",
    "* `page` = number: The API results are paginated with a max of 10 pages, meaning that to get all results that contain the SPAC keyword, we'll have to exhaust all pages.\n",
    "\n",
    "Formatting this API url to do a search for articles that include the word \"SPAC\" we get this URL\n",
    "\n",
    "```https://api.nytimes.com/svc/search/v2/articlesearch.json?q=SPAC&sort=oldest&page=1&api-key=yourkey```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_search_by_keyword(keyword: str, api_key: str, page=1): \n",
    "    \"\"\"Query the NYT article search API by keyword and return the response as a JSON object.\n",
    "    \n",
    "    @return None, Response: if the request fails\n",
    "    @return JSON object, Response: if the request succeeds\n",
    "    \"\"\"\n",
    "    url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?q=%s&page=%d&sort=newest&api-key=%s\" % (keyword, page, api_key)\n",
    "    res = requests.get(url)\n",
    "    if res.status_code != 200 or res.json()['response']['docs'] == []:\n",
    "        return None, res\n",
    "\n",
    "    return res.json(), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_res, _ = article_search_by_keyword(\"special purpose acquisition company\", os.getenv(\"NYT_API_KEY\"))\n",
    "# json_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_res[\"response\"][\"docs\"][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Our query worked. We're able to now make generalized HTTP requests to get article information from the New York Times!\n",
    "\n",
    "<iframe src=\"https://giphy.com/embed/l3q2zVr6cu95nF6O4\" width=\"480\" height=\"236\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/producthunt-party-parrot-parrots-l3q2zVr6cu95nF6O4\">via GIPHY</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract <class 'str'>\n",
      "web_url <class 'str'>\n",
      "snippet <class 'str'>\n",
      "lead_paragraph <class 'str'>\n",
      "print_section <class 'str'>\n",
      "print_page <class 'str'>\n",
      "source <class 'str'>\n",
      "multimedia <class 'list'>\n",
      "headline <class 'dict'>\n",
      "keywords <class 'list'>\n",
      "pub_date <class 'str'>\n",
      "document_type <class 'str'>\n",
      "news_desk <class 'str'>\n",
      "section_name <class 'str'>\n",
      "subsection_name <class 'str'>\n",
      "byline <class 'dict'>\n",
      "type_of_material <class 'str'>\n",
      "_id <class 'str'>\n",
      "word_count <class 'int'>\n",
      "uri <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for key in json_res['response']['docs'][0].keys():\n",
    "    print(key, type(json_res['response']['docs'][0][key]), sep=':\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the New York Times API results are paginated, that makes we can only get 10 articles at a time. On each API call, we're going to need to make a sequentially API call to next page, until we've exhausted all pages (and therefore received the complete data from the API query). We can not make all these requests at once other the NYT will rate limit us and prevent us from making requests. To work around then, after each request let's set a timeout period to wait between requests.\n",
    "\n",
    "**NOTE**: All the results of the API calls are saved in the `data/nyt` directory. This code is only left here to show how I collected the data and it's not recommended running it because of how long it takes. I had the script run on my computer overnight to get all the API results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_all_articles_for_keyword(keyword: str, api_key: str, max_page=100, sleep_time_sec=6, start_page=1):\n",
    "    \"\"\"Query the NYT article search API by keyword and return all the responses as a list of JSON objects.\n",
    "    \n",
    "    @return Response, Page: The response and page number of the last request when the request eventually fails\n",
    "    @return None: If the requests go past max_page\n",
    "    \"\"\"\n",
    "    os_friendly_keyword = keyword.replace(\" \", \"_\")\n",
    "\n",
    "    # Make the /data/nyt directory if it doesn't exist\n",
    "    if not os.path.exists(\"data/nyt/%s\" % os_friendly_keyword):\n",
    "        os.makedirs(\"data/nyt/%s\" % os_friendly_keyword)\n",
    "\n",
    "    for page in range(start_page, max_page + 1):\n",
    "        json_res, res = article_search_by_keyword(keyword, api_key, page)\n",
    "        if json_res is None:\n",
    "            return res, page\n",
    "        with open(\"data/nyt/%s/%s_%d.json\" % (os_friendly_keyword, os_friendly_keyword, page), \"w\") as f:\n",
    "            f.write(json.dumps(json_res))\n",
    "        print(\"%s: Finished page %d for keyword %s\" % (dt.datetime.now(), page, keyword))\n",
    "        # Have to sleep for rate timing\n",
    "        time.sleep(sleep_time_sec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This while loop will run until an API rate limit is exceeded or until max_page is reached\n",
    "\n",
    "start_page = 1\n",
    "while True:\n",
    "    num_rate_limits = 0\n",
    "    error_res, page = get_all_articles_for_keyword(\"special purpose acquisition company\", os.getenv(\"NYT_API_KEY\"), start_page=start_page, sleep_time_sec=10, max_page=300)\n",
    "    if type(error_res) == bytes or error_res.status_code == 429:\n",
    "        num_rate_limits += 1\n",
    "        if num_rate_limits > 10:\n",
    "            break\n",
    "        start_page = page\n",
    "        print(\"Rate limit exceeded, sleeping for 1 minute\")\n",
    "        time.sleep(60)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data Formatting\n",
    "\n",
    "## Combine the JSON Files to one dataframe for each keyword\n",
    "\n",
    "![Start Line](assets/start-line.jpeg)\n",
    "\n",
    "**NOTE:** If you want to run this notebook without doing the tedious data collection, start here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(data: dict):\n",
    "    \"\"\"Convert a JSON object from the NYT article search API to a pandas DataFrame.\n",
    "    \n",
    "    @return DataFrame: The DataFrame representation of the JSON object\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(data['response']['docs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>web_url</th>\n",
       "      <th>snippet</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>print_section</th>\n",
       "      <th>print_page</th>\n",
       "      <th>source</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>document_type</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>section_name</th>\n",
       "      <th>subsection_name</th>\n",
       "      <th>byline</th>\n",
       "      <th>type_of_material</th>\n",
       "      <th>_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The preliminary guidance applies to an alterna...</td>\n",
       "      <td>https://www.nytimes.com/2022/12/27/us/politics...</td>\n",
       "      <td>The preliminary guidance applies to an alterna...</td>\n",
       "      <td>WASHINGTON — The Treasury Department on Tuesda...</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'rank': 0, 'subtype': 'xlarge', 'caption': N...</td>\n",
       "      <td>{'main': 'Treasury Department Outlines Rules f...</td>\n",
       "      <td>[{'name': 'subject', 'value': 'United States P...</td>\n",
       "      <td>2022-12-27T22:58:06+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Washington</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Politics</td>\n",
       "      <td>{'original': 'By Jim Tankersley', 'person': [{...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/51e3a268-3b89-50c2-b801-3a750baa...</td>\n",
       "      <td>600</td>\n",
       "      <td>nyt://article/51e3a268-3b89-50c2-b801-3a750baa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There were fewer mergers and public listings t...</td>\n",
       "      <td>https://www.nytimes.com/2022/12/23/business/wa...</td>\n",
       "      <td>There were fewer mergers and public listings t...</td>\n",
       "      <td>The luxury travel bookings will be more subdue...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'rank': 0, 'subtype': 'xlarge', 'caption': N...</td>\n",
       "      <td>{'main': 'For Many Wall Street Bankers, This Y...</td>\n",
       "      <td>[{'name': 'subject', 'value': 'Banking and Fin...</td>\n",
       "      <td>2022-12-23T08:00:10+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'original': 'By Maureen Farrell, Lauren Hirsc...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/eaabf5ae-6d5d-5663-b8e2-2fa46f64...</td>\n",
       "      <td>1321</td>\n",
       "      <td>nyt://article/eaabf5ae-6d5d-5663-b8e2-2fa46f64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An I.R.S. policy requires the agency audit pre...</td>\n",
       "      <td>https://www.nytimes.com/interactive/2022/12/21...</td>\n",
       "      <td>An I.R.S. policy requires the agency audit pre...</td>\n",
       "      <td>An I.R.S. policy requires the agency audit pre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'rank': 0, 'subtype': 'xlarge', 'caption': N...</td>\n",
       "      <td>{'main': 'Document: Report on the I.R.S. Manda...</td>\n",
       "      <td>[{'name': 'subject', 'value': 'Trump Tax Retur...</td>\n",
       "      <td>2022-12-21T02:28:23+0000</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Politics</td>\n",
       "      <td>{'original': None, 'person': [], 'organization...</td>\n",
       "      <td>Interactive Feature</td>\n",
       "      <td>nyt://interactive/e07fa384-7481-51b5-8d82-6a46...</td>\n",
       "      <td>0</td>\n",
       "      <td>nyt://interactive/e07fa384-7481-51b5-8d82-6a46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chamath Palihapitiya, once a relentless cheerl...</td>\n",
       "      <td>https://www.nytimes.com/2022/12/07/business/ch...</td>\n",
       "      <td>Chamath Palihapitiya, once a relentless cheerl...</td>\n",
       "      <td>Not long ago, Chamath Palihapitiya could be ca...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'rank': 0, 'subtype': 'xlarge', 'caption': N...</td>\n",
       "      <td>{'main': 'The ‘SPAC King’ Is Over It', 'kicker...</td>\n",
       "      <td>[{'name': 'persons', 'value': 'Palihapitiya, C...</td>\n",
       "      <td>2022-12-07T10:00:35+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'original': 'By Maureen Farrell', 'person': [...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/26f371d9-968c-54e3-a955-cdbc8880...</td>\n",
       "      <td>1748</td>\n",
       "      <td>nyt://article/26f371d9-968c-54e3-a955-cdbc8880...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yahoo’s chief executive sees the deal as a lon...</td>\n",
       "      <td>https://www.nytimes.com/2022/11/28/business/de...</td>\n",
       "      <td>Yahoo’s chief executive sees the deal as a lon...</td>\n",
       "      <td>Yahoo is deepening its push into digital adver...</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'rank': 0, 'subtype': 'xlarge', 'caption': N...</td>\n",
       "      <td>{'main': 'Yahoo Takes Minority Stake in Ad Net...</td>\n",
       "      <td>[{'name': 'subject', 'value': 'Computers and t...</td>\n",
       "      <td>2022-11-28T11:00:08+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>DealBook</td>\n",
       "      <td>{'original': 'By Lauren Hirsch and Benjamin Mu...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/9cef1d89-b296-52aa-adc9-c75b69fc...</td>\n",
       "      <td>679</td>\n",
       "      <td>nyt://article/9cef1d89-b296-52aa-adc9-c75b69fc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  The preliminary guidance applies to an alterna...   \n",
       "1  There were fewer mergers and public listings t...   \n",
       "2  An I.R.S. policy requires the agency audit pre...   \n",
       "3  Chamath Palihapitiya, once a relentless cheerl...   \n",
       "4  Yahoo’s chief executive sees the deal as a lon...   \n",
       "\n",
       "                                             web_url  \\\n",
       "0  https://www.nytimes.com/2022/12/27/us/politics...   \n",
       "1  https://www.nytimes.com/2022/12/23/business/wa...   \n",
       "2  https://www.nytimes.com/interactive/2022/12/21...   \n",
       "3  https://www.nytimes.com/2022/12/07/business/ch...   \n",
       "4  https://www.nytimes.com/2022/11/28/business/de...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  The preliminary guidance applies to an alterna...   \n",
       "1  There were fewer mergers and public listings t...   \n",
       "2  An I.R.S. policy requires the agency audit pre...   \n",
       "3  Chamath Palihapitiya, once a relentless cheerl...   \n",
       "4  Yahoo’s chief executive sees the deal as a lon...   \n",
       "\n",
       "                                      lead_paragraph print_section print_page  \\\n",
       "0  WASHINGTON — The Treasury Department on Tuesda...             A         16   \n",
       "1  The luxury travel bookings will be more subdue...             B          1   \n",
       "2  An I.R.S. policy requires the agency audit pre...           NaN        NaN   \n",
       "3  Not long ago, Chamath Palihapitiya could be ca...             B          1   \n",
       "4  Yahoo is deepening its push into digital adver...             B          3   \n",
       "\n",
       "               source                                         multimedia  \\\n",
       "0  The New York Times  [{'rank': 0, 'subtype': 'xlarge', 'caption': N...   \n",
       "1  The New York Times  [{'rank': 0, 'subtype': 'xlarge', 'caption': N...   \n",
       "2  The New York Times  [{'rank': 0, 'subtype': 'xlarge', 'caption': N...   \n",
       "3  The New York Times  [{'rank': 0, 'subtype': 'xlarge', 'caption': N...   \n",
       "4  The New York Times  [{'rank': 0, 'subtype': 'xlarge', 'caption': N...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  {'main': 'Treasury Department Outlines Rules f...   \n",
       "1  {'main': 'For Many Wall Street Bankers, This Y...   \n",
       "2  {'main': 'Document: Report on the I.R.S. Manda...   \n",
       "3  {'main': 'The ‘SPAC King’ Is Over It', 'kicker...   \n",
       "4  {'main': 'Yahoo Takes Minority Stake in Ad Net...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [{'name': 'subject', 'value': 'United States P...   \n",
       "1  [{'name': 'subject', 'value': 'Banking and Fin...   \n",
       "2  [{'name': 'subject', 'value': 'Trump Tax Retur...   \n",
       "3  [{'name': 'persons', 'value': 'Palihapitiya, C...   \n",
       "4  [{'name': 'subject', 'value': 'Computers and t...   \n",
       "\n",
       "                   pub_date document_type   news_desk  section_name  \\\n",
       "0  2022-12-27T22:58:06+0000       article  Washington          U.S.   \n",
       "1  2022-12-23T08:00:10+0000       article    Business  Business Day   \n",
       "2  2022-12-21T02:28:23+0000    multimedia        U.S.          U.S.   \n",
       "3  2022-12-07T10:00:35+0000       article    Business  Business Day   \n",
       "4  2022-11-28T11:00:08+0000       article    Business  Business Day   \n",
       "\n",
       "  subsection_name                                             byline  \\\n",
       "0        Politics  {'original': 'By Jim Tankersley', 'person': [{...   \n",
       "1             NaN  {'original': 'By Maureen Farrell, Lauren Hirsc...   \n",
       "2        Politics  {'original': None, 'person': [], 'organization...   \n",
       "3             NaN  {'original': 'By Maureen Farrell', 'person': [...   \n",
       "4        DealBook  {'original': 'By Lauren Hirsch and Benjamin Mu...   \n",
       "\n",
       "      type_of_material                                                _id  \\\n",
       "0                 News  nyt://article/51e3a268-3b89-50c2-b801-3a750baa...   \n",
       "1                 News  nyt://article/eaabf5ae-6d5d-5663-b8e2-2fa46f64...   \n",
       "2  Interactive Feature  nyt://interactive/e07fa384-7481-51b5-8d82-6a46...   \n",
       "3                 News  nyt://article/26f371d9-968c-54e3-a955-cdbc8880...   \n",
       "4                 News  nyt://article/9cef1d89-b296-52aa-adc9-c75b69fc...   \n",
       "\n",
       "   word_count                                                uri  \n",
       "0         600  nyt://article/51e3a268-3b89-50c2-b801-3a750baa...  \n",
       "1        1321  nyt://article/eaabf5ae-6d5d-5663-b8e2-2fa46f64...  \n",
       "2           0  nyt://interactive/e07fa384-7481-51b5-8d82-6a46...  \n",
       "3        1748  nyt://article/26f371d9-968c-54e3-a955-cdbc8880...  \n",
       "4         679  nyt://article/9cef1d89-b296-52aa-adc9-c75b69fc...  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/nyt/special_purpose_acquisition_company/special_purpose_acquisition_company_1.json\", \"r\") as f:\n",
    "    json_res = json.loads(f.read())\n",
    "    df = json_to_df(json_res)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>web_url</th>\n",
       "      <th>snippet</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>print_section</th>\n",
       "      <th>print_page</th>\n",
       "      <th>source</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>document_type</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>section_name</th>\n",
       "      <th>byline</th>\n",
       "      <th>type_of_material</th>\n",
       "      <th>_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>uri</th>\n",
       "      <th>subsection_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The company’s top executive resigned after the...</td>\n",
       "      <td>https://www.nytimes.com/2021/06/14/business/lo...</td>\n",
       "      <td>The company’s top executive resigned after the...</td>\n",
       "      <td>When Mary T. Barra, the chief executive of Gen...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'rank': 0, 'subtype': 'xlarge', 'caption': N...</td>\n",
       "      <td>{'main': 'Lordstown, Truck Maker That Can’t Af...</td>\n",
       "      <td>[{'name': 'organizations', 'value': 'Lordstown...</td>\n",
       "      <td>2021-06-14T12:07:16+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>{'original': 'By Matthew Goldstein, Lauren Hir...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/da4c9fa3-556e-5989-8b6f-9ec45506...</td>\n",
       "      <td>1406</td>\n",
       "      <td>nyt://article/da4c9fa3-556e-5989-8b6f-9ec45506...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How a powerful industry conquered the U.S. tax...</td>\n",
       "      <td>https://www.nytimes.com/2021/06/14/business/de...</td>\n",
       "      <td>How a powerful industry conquered the U.S. tax...</td>\n",
       "      <td>The $4.5 trillion buyout industry “has perfect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'rank': 0, 'subtype': 'xlarge', 'caption': N...</td>\n",
       "      <td>{'main': 'Private Equity’s Biggest Tax Tactics...</td>\n",
       "      <td>[{'name': 'subject', 'value': 'Federal Taxes (...</td>\n",
       "      <td>2021-06-14T11:23:32+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>{'original': 'By Andrew Ross Sorkin, Jason Kar...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/b3308881-073f-5092-bd37-77f2a034...</td>\n",
       "      <td>1779</td>\n",
       "      <td>nyt://article/b3308881-073f-5092-bd37-77f2a034...</td>\n",
       "      <td>DealBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These complex takeover vehicles serve an impor...</td>\n",
       "      <td>https://www.nytimes.com/2021/06/12/business/de...</td>\n",
       "      <td>These complex takeover vehicles serve an impor...</td>\n",
       "      <td>The DealBook newsletter delves into a single t...</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'rank': 0, 'subtype': 'xlarge', 'caption': N...</td>\n",
       "      <td>{'main': 'In Defense of SPACs', 'kicker': 'dea...</td>\n",
       "      <td>[{'name': 'subject', 'value': 'Special Purpose...</td>\n",
       "      <td>2021-06-12T12:00:04+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>{'original': 'By Steven Davidoff Solomon', 'pe...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/91942d03-2916-523f-8906-9b578f19...</td>\n",
       "      <td>997</td>\n",
       "      <td>nyt://article/91942d03-2916-523f-8906-9b578f19...</td>\n",
       "      <td>DealBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inside Silicon Valley’s 10-year quest to make ...</td>\n",
       "      <td>https://www.nytimes.com/2021/06/12/technology/...</td>\n",
       "      <td>Inside Silicon Valley’s 10-year quest to make ...</td>\n",
       "      <td>To hear more audio stories from publications l...</td>\n",
       "      <td>BU</td>\n",
       "      <td>1</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'main': 'What Is a Flying Car?', 'kicker': No...</td>\n",
       "      <td>[{'name': 'subject', 'value': 'Flying Cars', '...</td>\n",
       "      <td>2021-06-12T09:00:30+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>SundayBusiness</td>\n",
       "      <td>Technology</td>\n",
       "      <td>{'original': 'By Cade Metz and Erin Griffith',...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/d96f1acf-8d87-5298-969f-0af0b491...</td>\n",
       "      <td>2340</td>\n",
       "      <td>nyt://article/d96f1acf-8d87-5298-969f-0af0b491...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It’s been a blowout year for executive pay.</td>\n",
       "      <td>https://www.nytimes.com/2021/06/11/business/de...</td>\n",
       "      <td>It’s been a blowout year for executive pay.</td>\n",
       "      <td>Want to get the DealBook newsletter in your in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'rank': 0, 'subtype': 'xlarge', 'caption': N...</td>\n",
       "      <td>{'main': 'Behold the Highest-Paid C.E.O.s', 'k...</td>\n",
       "      <td>[{'name': 'subject', 'value': 'Executive Compe...</td>\n",
       "      <td>2021-06-11T11:55:35+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>{'original': 'By Andrew Ross Sorkin, Jason Kar...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/2fad74da-fca3-54e4-9e46-90851df7...</td>\n",
       "      <td>1367</td>\n",
       "      <td>nyt://article/2fad74da-fca3-54e4-9e46-90851df7...</td>\n",
       "      <td>DealBook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  The company’s top executive resigned after the...   \n",
       "1  How a powerful industry conquered the U.S. tax...   \n",
       "2  These complex takeover vehicles serve an impor...   \n",
       "3  Inside Silicon Valley’s 10-year quest to make ...   \n",
       "4        It’s been a blowout year for executive pay.   \n",
       "\n",
       "                                             web_url  \\\n",
       "0  https://www.nytimes.com/2021/06/14/business/lo...   \n",
       "1  https://www.nytimes.com/2021/06/14/business/de...   \n",
       "2  https://www.nytimes.com/2021/06/12/business/de...   \n",
       "3  https://www.nytimes.com/2021/06/12/technology/...   \n",
       "4  https://www.nytimes.com/2021/06/11/business/de...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  The company’s top executive resigned after the...   \n",
       "1  How a powerful industry conquered the U.S. tax...   \n",
       "2  These complex takeover vehicles serve an impor...   \n",
       "3  Inside Silicon Valley’s 10-year quest to make ...   \n",
       "4        It’s been a blowout year for executive pay.   \n",
       "\n",
       "                                      lead_paragraph print_section print_page  \\\n",
       "0  When Mary T. Barra, the chief executive of Gen...             A          1   \n",
       "1  The $4.5 trillion buyout industry “has perfect...           NaN        NaN   \n",
       "2  The DealBook newsletter delves into a single t...             B          3   \n",
       "3  To hear more audio stories from publications l...            BU          1   \n",
       "4  Want to get the DealBook newsletter in your in...           NaN        NaN   \n",
       "\n",
       "               source                                         multimedia  \\\n",
       "0  The New York Times  [{'rank': 0, 'subtype': 'xlarge', 'caption': N...   \n",
       "1  The New York Times  [{'rank': 0, 'subtype': 'xlarge', 'caption': N...   \n",
       "2  The New York Times  [{'rank': 0, 'subtype': 'xlarge', 'caption': N...   \n",
       "3  The New York Times                                                 []   \n",
       "4  The New York Times  [{'rank': 0, 'subtype': 'xlarge', 'caption': N...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  {'main': 'Lordstown, Truck Maker That Can’t Af...   \n",
       "1  {'main': 'Private Equity’s Biggest Tax Tactics...   \n",
       "2  {'main': 'In Defense of SPACs', 'kicker': 'dea...   \n",
       "3  {'main': 'What Is a Flying Car?', 'kicker': No...   \n",
       "4  {'main': 'Behold the Highest-Paid C.E.O.s', 'k...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [{'name': 'organizations', 'value': 'Lordstown...   \n",
       "1  [{'name': 'subject', 'value': 'Federal Taxes (...   \n",
       "2  [{'name': 'subject', 'value': 'Special Purpose...   \n",
       "3  [{'name': 'subject', 'value': 'Flying Cars', '...   \n",
       "4  [{'name': 'subject', 'value': 'Executive Compe...   \n",
       "\n",
       "                   pub_date document_type       news_desk  section_name  \\\n",
       "0  2021-06-14T12:07:16+0000       article        Business  Business Day   \n",
       "1  2021-06-14T11:23:32+0000       article        Business  Business Day   \n",
       "2  2021-06-12T12:00:04+0000       article        Business  Business Day   \n",
       "3  2021-06-12T09:00:30+0000       article  SundayBusiness    Technology   \n",
       "4  2021-06-11T11:55:35+0000       article        Business  Business Day   \n",
       "\n",
       "                                              byline type_of_material  \\\n",
       "0  {'original': 'By Matthew Goldstein, Lauren Hir...             News   \n",
       "1  {'original': 'By Andrew Ross Sorkin, Jason Kar...             News   \n",
       "2  {'original': 'By Steven Davidoff Solomon', 'pe...             News   \n",
       "3  {'original': 'By Cade Metz and Erin Griffith',...             News   \n",
       "4  {'original': 'By Andrew Ross Sorkin, Jason Kar...             News   \n",
       "\n",
       "                                                 _id  word_count  \\\n",
       "0  nyt://article/da4c9fa3-556e-5989-8b6f-9ec45506...        1406   \n",
       "1  nyt://article/b3308881-073f-5092-bd37-77f2a034...        1779   \n",
       "2  nyt://article/91942d03-2916-523f-8906-9b578f19...         997   \n",
       "3  nyt://article/d96f1acf-8d87-5298-969f-0af0b491...        2340   \n",
       "4  nyt://article/2fad74da-fca3-54e4-9e46-90851df7...        1367   \n",
       "\n",
       "                                                 uri subsection_name  \n",
       "0  nyt://article/da4c9fa3-556e-5989-8b6f-9ec45506...             NaN  \n",
       "1  nyt://article/b3308881-073f-5092-bd37-77f2a034...        DealBook  \n",
       "2  nyt://article/91942d03-2916-523f-8906-9b578f19...        DealBook  \n",
       "3  nyt://article/d96f1acf-8d87-5298-969f-0af0b491...             NaN  \n",
       "4  nyt://article/2fad74da-fca3-54e4-9e46-90851df7...        DealBook  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all the JSON files in the SPAC and the special_purpose_acquisition_company directories into their respective DataFrame\n",
    "\n",
    "spac_df = pd.DataFrame()\n",
    "for file in os.listdir(\"data/nyt/spac\"):\n",
    "    with open(\"data/nyt/spac/%s\" % file, \"r\") as f:\n",
    "        json_res = json.loads(f.read())\n",
    "        spac_df = pd.concat([spac_df, json_to_df(json_res)]) \n",
    "\n",
    "\n",
    "spac_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>web_url</th>\n",
       "      <th>snippet</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>print_section</th>\n",
       "      <th>print_page</th>\n",
       "      <th>source</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>document_type</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>section_name</th>\n",
       "      <th>byline</th>\n",
       "      <th>type_of_material</th>\n",
       "      <th>_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>uri</th>\n",
       "      <th>subsection_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Article on report released by Small Business A...</td>\n",
       "      <td>https://www.nytimes.com/2005/02/22/business/bu...</td>\n",
       "      <td>Article on report released by Small Business A...</td>\n",
       "      <td>ARE small businesses actually getting all the ...</td>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'main': 'Case of the Missing Set-Aside', 'kic...</td>\n",
       "      <td>[{'name': 'organizations', 'value': 'Small Bus...</td>\n",
       "      <td>2005-02-22T05:00:00+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>{'original': 'By Bernard Stamler', 'person': [...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/bd7136af-4eab-51c7-83eb-85272fd1...</td>\n",
       "      <td>1041</td>\n",
       "      <td>nyt://article/bd7136af-4eab-51c7-83eb-85272fd1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Article on win-win situation involving joint a...</td>\n",
       "      <td>https://www.nytimes.com/2005/02/20/nyregion/de...</td>\n",
       "      <td>Article on win-win situation involving joint a...</td>\n",
       "      <td>THE joint acquisition of more than a square mi...</td>\n",
       "      <td>WC</td>\n",
       "      <td>14</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'main': 'In Somers, An Investment For Everyon...</td>\n",
       "      <td>[{'name': 'glocations', 'value': 'Somers (NY)'...</td>\n",
       "      <td>2005-02-20T05:00:00+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Westchester Weekly Desk</td>\n",
       "      <td>New York</td>\n",
       "      <td>{'original': 'By Elsa Brenner', 'person': [{'f...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/a4955910-dd79-55ad-b18c-e18ddba7...</td>\n",
       "      <td>1044</td>\n",
       "      <td>nyt://article/a4955910-dd79-55ad-b18c-e18ddba7...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Profile of Jane Friedman, chief executive of H...</td>\n",
       "      <td>https://www.nytimes.com/2005/02/06/business/yo...</td>\n",
       "      <td>Profile of Jane Friedman, chief executive of H...</td>\n",
       "      <td>Correction Appended</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'main': 'Michael Crichton? He's Just the Auth...</td>\n",
       "      <td>[{'name': 'organizations', 'value': 'NEWS CORP...</td>\n",
       "      <td>2005-02-06T05:00:00+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>SundayBusiness</td>\n",
       "      <td>Books</td>\n",
       "      <td>{'original': 'By Edward Wyatt', 'person': [{'f...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/fbdd8b9b-c467-53d2-9345-0919752e...</td>\n",
       "      <td>2449</td>\n",
       "      <td>nyt://article/fbdd8b9b-c467-53d2-9345-0919752e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Earlier this month, Johnson &amp; Johnson became o...</td>\n",
       "      <td>https://www.nytimes.com/2005/01/30/opinion/cor...</td>\n",
       "      <td>Earlier this month, Johnson &amp; Johnson became o...</td>\n",
       "      <td>Earlier this month, Johnson &amp; Johnson became o...</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'main': 'Corporate Welfare Runs Amok', 'kicke...</td>\n",
       "      <td>[{'name': 'glocations', 'value': 'United State...</td>\n",
       "      <td>2005-01-30T05:00:00+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Editorial Desk</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>{'original': None, 'person': [], 'organization...</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>nyt://article/f60acba6-6b87-5e89-93d9-8c903413...</td>\n",
       "      <td>681</td>\n",
       "      <td>nyt://article/f60acba6-6b87-5e89-93d9-8c903413...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MICK JAGGER was there that night in 1996, watc...</td>\n",
       "      <td>https://www.nytimes.com/2004/12/26/business/dr...</td>\n",
       "      <td>MICK JAGGER was there that night in 1996, watc...</td>\n",
       "      <td>MICK JAGGER was there that night in 1996, watc...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'main': 'Dressing Down Tommy Hilfiger', 'kick...</td>\n",
       "      <td>[{'name': 'subject', 'value': 'APPAREL', 'rank...</td>\n",
       "      <td>2004-12-26T05:00:00+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>SundayBusiness</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>{'original': 'By Tracie Rozhon', 'person': [{'...</td>\n",
       "      <td>News</td>\n",
       "      <td>nyt://article/743bf758-5cf9-51c0-816c-cf5690ec...</td>\n",
       "      <td>3432</td>\n",
       "      <td>nyt://article/743bf758-5cf9-51c0-816c-cf5690ec...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  Article on report released by Small Business A...   \n",
       "1  Article on win-win situation involving joint a...   \n",
       "2  Profile of Jane Friedman, chief executive of H...   \n",
       "3  Earlier this month, Johnson & Johnson became o...   \n",
       "4  MICK JAGGER was there that night in 1996, watc...   \n",
       "\n",
       "                                             web_url  \\\n",
       "0  https://www.nytimes.com/2005/02/22/business/bu...   \n",
       "1  https://www.nytimes.com/2005/02/20/nyregion/de...   \n",
       "2  https://www.nytimes.com/2005/02/06/business/yo...   \n",
       "3  https://www.nytimes.com/2005/01/30/opinion/cor...   \n",
       "4  https://www.nytimes.com/2004/12/26/business/dr...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  Article on report released by Small Business A...   \n",
       "1  Article on win-win situation involving joint a...   \n",
       "2  Profile of Jane Friedman, chief executive of H...   \n",
       "3  Earlier this month, Johnson & Johnson became o...   \n",
       "4  MICK JAGGER was there that night in 1996, watc...   \n",
       "\n",
       "                                      lead_paragraph print_section print_page  \\\n",
       "0  ARE small businesses actually getting all the ...             G          9   \n",
       "1  THE joint acquisition of more than a square mi...            WC         14   \n",
       "2                                Correction Appended             3          1   \n",
       "3  Earlier this month, Johnson & Johnson became o...             4         16   \n",
       "4  MICK JAGGER was there that night in 1996, watc...             3          1   \n",
       "\n",
       "               source multimedia  \\\n",
       "0  The New York Times         []   \n",
       "1  The New York Times         []   \n",
       "2  The New York Times         []   \n",
       "3  The New York Times         []   \n",
       "4  The New York Times         []   \n",
       "\n",
       "                                            headline  \\\n",
       "0  {'main': 'Case of the Missing Set-Aside', 'kic...   \n",
       "1  {'main': 'In Somers, An Investment For Everyon...   \n",
       "2  {'main': 'Michael Crichton? He's Just the Auth...   \n",
       "3  {'main': 'Corporate Welfare Runs Amok', 'kicke...   \n",
       "4  {'main': 'Dressing Down Tommy Hilfiger', 'kick...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [{'name': 'organizations', 'value': 'Small Bus...   \n",
       "1  [{'name': 'glocations', 'value': 'Somers (NY)'...   \n",
       "2  [{'name': 'organizations', 'value': 'NEWS CORP...   \n",
       "3  [{'name': 'glocations', 'value': 'United State...   \n",
       "4  [{'name': 'subject', 'value': 'APPAREL', 'rank...   \n",
       "\n",
       "                   pub_date document_type                news_desk  \\\n",
       "0  2005-02-22T05:00:00+0000       article           Small Business   \n",
       "1  2005-02-20T05:00:00+0000       article  Westchester Weekly Desk   \n",
       "2  2005-02-06T05:00:00+0000       article           SundayBusiness   \n",
       "3  2005-01-30T05:00:00+0000       article           Editorial Desk   \n",
       "4  2004-12-26T05:00:00+0000       article           SundayBusiness   \n",
       "\n",
       "   section_name                                             byline  \\\n",
       "0  Business Day  {'original': 'By Bernard Stamler', 'person': [...   \n",
       "1      New York  {'original': 'By Elsa Brenner', 'person': [{'f...   \n",
       "2         Books  {'original': 'By Edward Wyatt', 'person': [{'f...   \n",
       "3       Opinion  {'original': None, 'person': [], 'organization...   \n",
       "4  Business Day  {'original': 'By Tracie Rozhon', 'person': [{'...   \n",
       "\n",
       "  type_of_material                                                _id  \\\n",
       "0             News  nyt://article/bd7136af-4eab-51c7-83eb-85272fd1...   \n",
       "1             News  nyt://article/a4955910-dd79-55ad-b18c-e18ddba7...   \n",
       "2             News  nyt://article/fbdd8b9b-c467-53d2-9345-0919752e...   \n",
       "3        Editorial  nyt://article/f60acba6-6b87-5e89-93d9-8c903413...   \n",
       "4             News  nyt://article/743bf758-5cf9-51c0-816c-cf5690ec...   \n",
       "\n",
       "   word_count                                                uri  \\\n",
       "0        1041  nyt://article/bd7136af-4eab-51c7-83eb-85272fd1...   \n",
       "1        1044  nyt://article/a4955910-dd79-55ad-b18c-e18ddba7...   \n",
       "2        2449  nyt://article/fbdd8b9b-c467-53d2-9345-0919752e...   \n",
       "3         681  nyt://article/f60acba6-6b87-5e89-93d9-8c903413...   \n",
       "4        3432  nyt://article/743bf758-5cf9-51c0-816c-cf5690ec...   \n",
       "\n",
       "  subsection_name  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose_spac_df = pd.DataFrame()\n",
    "for file in os.listdir(\"data/nyt/special_purpose_acquisition_company\"):\n",
    "    with open(\"data/nyt/special_purpose_acquisition_company/%s\" % file, \"r\") as f:\n",
    "        json_res = json.loads(f.read())\n",
    "        verbose_spac_df = pd.concat([verbose_spac_df, json_to_df(json_res)])\n",
    "\n",
    "verbose_spac_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(585, 20)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spac_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose_spac_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((585,), (2000,))"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are duplicate articles in the spac_df and verbose_spac_df\n",
    "spac_df['_id'].unique().shape, verbose_spac_df['_id'].unique().shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the DataFrames, removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>web_url</th>\n",
       "      <th>snippet</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>print_section</th>\n",
       "      <th>print_page</th>\n",
       "      <th>source</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>document_type</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>section_name</th>\n",
       "      <th>byline</th>\n",
       "      <th>type_of_material</th>\n",
       "      <th>word_count</th>\n",
       "      <th>uri</th>\n",
       "      <th>subsection_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nyt://article/00333e27-a5aa-5453-a0fe-2489f23c...</td>\n",
       "      <td>(This article was reported by C. J. Chivers, E...</td>\n",
       "      <td>https://www.nytimes.com/2008/03/27/world/asia/...</td>\n",
       "      <td></td>\n",
       "      <td>(This article was reported by C. J. Chivers, E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>International Herald Tribune</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'main': 'Supplier under scrutiny on aging arm...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2008-03-27T05:00:00+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>IHT News</td>\n",
       "      <td>World</td>\n",
       "      <td>{'original': 'By C. J. Chivers', 'person': [{'...</td>\n",
       "      <td>News</td>\n",
       "      <td>4219</td>\n",
       "      <td>nyt://article/00333e27-a5aa-5453-a0fe-2489f23c...</td>\n",
       "      <td>Asia Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nyt://article/003a5b2f-bfe7-5b1e-a049-8a4d372e...</td>\n",
       "      <td>The corporate practice of siphoning money fr...</td>\n",
       "      <td>https://www.nytimes.com/1983/09/25/business/pr...</td>\n",
       "      <td></td>\n",
       "      <td>The corporate practice of siphoning money from...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'main': 'Raiding Pension Plan', 'kicker': 'PR...</td>\n",
       "      <td>[{'name': 'subject', 'value': 'TERMS NOT AVAIL...</td>\n",
       "      <td>1983-09-25T05:00:00+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Financial Desk</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>{'original': 'By Clyde H. Farnsworth', 'person...</td>\n",
       "      <td>Summary</td>\n",
       "      <td>765</td>\n",
       "      <td>nyt://article/003a5b2f-bfe7-5b1e-a049-8a4d372e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nyt://article/004f83e0-4289-5034-8eda-3f0d06c9...</td>\n",
       "      <td>Gary Gensler, the new S.E.C. chairman, wants t...</td>\n",
       "      <td>https://www.nytimes.com/2021/04/21/business/ec...</td>\n",
       "      <td>Gary Gensler, the new S.E.C. chairman, wants t...</td>\n",
       "      <td>Wall Street’s new watchdog, Gary Gensler, is c...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[{'rank': 0, 'subtype': 'xlarge', 'caption': N...</td>\n",
       "      <td>{'main': 'Manic Markets, Imploding Funds: Wall...</td>\n",
       "      <td>[{'name': 'persons', 'value': 'Gensler, Gary S...</td>\n",
       "      <td>2021-04-21T14:05:15+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>{'original': 'By Matthew Goldstein', 'person':...</td>\n",
       "      <td>News</td>\n",
       "      <td>1286</td>\n",
       "      <td>nyt://article/004f83e0-4289-5034-8eda-3f0d06c9...</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nyt://article/0056b3ce-dd83-5c26-9928-37d4f654...</td>\n",
       "      <td>Biog; illus</td>\n",
       "      <td>https://www.nytimes.com/1961/09/06/archives/co...</td>\n",
       "      <td>Biog; illus</td>\n",
       "      <td></td>\n",
       "      <td>BUSINESS FINANCIAL</td>\n",
       "      <td>51</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'main': 'Co-Existence in the Retail War; Disc...</td>\n",
       "      <td>[{'name': 'organizations', 'value': 'GRAYSON-R...</td>\n",
       "      <td>1961-09-06T05:00:00+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>None</td>\n",
       "      <td>Archives</td>\n",
       "      <td>{'original': 'By William M. Freeman', 'person'...</td>\n",
       "      <td>Archives</td>\n",
       "      <td>0</td>\n",
       "      <td>nyt://article/0056b3ce-dd83-5c26-9928-37d4f654...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nyt://article/006fe0c5-ffc3-5ed1-9ec8-eed97e51...</td>\n",
       "      <td>Lehman message</td>\n",
       "      <td>https://www.nytimes.com/1938/01/06/archives/te...</td>\n",
       "      <td>Lehman message</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'main': 'Text of Governor Lehman's Annual Mes...</td>\n",
       "      <td>[{'name': 'glocations', 'value': 'New York Sta...</td>\n",
       "      <td>1938-01-06T05:00:00+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>None</td>\n",
       "      <td>Archives</td>\n",
       "      <td>{'original': 'Special to THE NEW YORK TIMES', ...</td>\n",
       "      <td>Archives</td>\n",
       "      <td>0</td>\n",
       "      <td>nyt://article/006fe0c5-ffc3-5ed1-9ec8-eed97e51...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 _id  \\\n",
       "0  nyt://article/00333e27-a5aa-5453-a0fe-2489f23c...   \n",
       "1  nyt://article/003a5b2f-bfe7-5b1e-a049-8a4d372e...   \n",
       "2  nyt://article/004f83e0-4289-5034-8eda-3f0d06c9...   \n",
       "3  nyt://article/0056b3ce-dd83-5c26-9928-37d4f654...   \n",
       "4  nyt://article/006fe0c5-ffc3-5ed1-9ec8-eed97e51...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  (This article was reported by C. J. Chivers, E...   \n",
       "1    The corporate practice of siphoning money fr...   \n",
       "2  Gary Gensler, the new S.E.C. chairman, wants t...   \n",
       "3                                        Biog; illus   \n",
       "4                                     Lehman message   \n",
       "\n",
       "                                             web_url  \\\n",
       "0  https://www.nytimes.com/2008/03/27/world/asia/...   \n",
       "1  https://www.nytimes.com/1983/09/25/business/pr...   \n",
       "2  https://www.nytimes.com/2021/04/21/business/ec...   \n",
       "3  https://www.nytimes.com/1961/09/06/archives/co...   \n",
       "4  https://www.nytimes.com/1938/01/06/archives/te...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  Gary Gensler, the new S.E.C. chairman, wants t...   \n",
       "3                                        Biog; illus   \n",
       "4                                     Lehman message   \n",
       "\n",
       "                                      lead_paragraph       print_section  \\\n",
       "0  (This article was reported by C. J. Chivers, E...                 NaN   \n",
       "1  The corporate practice of siphoning money from...                   3   \n",
       "2  Wall Street’s new watchdog, Gary Gensler, is c...                   B   \n",
       "3                                                     BUSINESS FINANCIAL   \n",
       "4                                                                    NaN   \n",
       "\n",
       "  print_page                        source  \\\n",
       "0        NaN  International Herald Tribune   \n",
       "1          1            The New York Times   \n",
       "2          1            The New York Times   \n",
       "3         51            The New York Times   \n",
       "4         14            The New York Times   \n",
       "\n",
       "                                          multimedia  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'rank': 0, 'subtype': 'xlarge', 'caption': N...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                            headline  \\\n",
       "0  {'main': 'Supplier under scrutiny on aging arm...   \n",
       "1  {'main': 'Raiding Pension Plan', 'kicker': 'PR...   \n",
       "2  {'main': 'Manic Markets, Imploding Funds: Wall...   \n",
       "3  {'main': 'Co-Existence in the Retail War; Disc...   \n",
       "4  {'main': 'Text of Governor Lehman's Annual Mes...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0                                                 []   \n",
       "1  [{'name': 'subject', 'value': 'TERMS NOT AVAIL...   \n",
       "2  [{'name': 'persons', 'value': 'Gensler, Gary S...   \n",
       "3  [{'name': 'organizations', 'value': 'GRAYSON-R...   \n",
       "4  [{'name': 'glocations', 'value': 'New York Sta...   \n",
       "\n",
       "                   pub_date document_type       news_desk  section_name  \\\n",
       "0  2008-03-27T05:00:00+0000       article        IHT News         World   \n",
       "1  1983-09-25T05:00:00+0000       article  Financial Desk  Business Day   \n",
       "2  2021-04-21T14:05:15+0000       article        Business  Business Day   \n",
       "3  1961-09-06T05:00:00+0000       article            None      Archives   \n",
       "4  1938-01-06T05:00:00+0000       article            None      Archives   \n",
       "\n",
       "                                              byline type_of_material  \\\n",
       "0  {'original': 'By C. J. Chivers', 'person': [{'...             News   \n",
       "1  {'original': 'By Clyde H. Farnsworth', 'person...          Summary   \n",
       "2  {'original': 'By Matthew Goldstein', 'person':...             News   \n",
       "3  {'original': 'By William M. Freeman', 'person'...         Archives   \n",
       "4  {'original': 'Special to THE NEW YORK TIMES', ...         Archives   \n",
       "\n",
       "   word_count                                                uri  \\\n",
       "0        4219  nyt://article/00333e27-a5aa-5453-a0fe-2489f23c...   \n",
       "1         765  nyt://article/003a5b2f-bfe7-5b1e-a049-8a4d372e...   \n",
       "2        1286  nyt://article/004f83e0-4289-5034-8eda-3f0d06c9...   \n",
       "3           0  nyt://article/0056b3ce-dd83-5c26-9928-37d4f654...   \n",
       "4           0  nyt://article/006fe0c5-ffc3-5ed1-9ec8-eed97e51...   \n",
       "\n",
       "  subsection_name  \n",
       "0    Asia Pacific  \n",
       "1             NaN  \n",
       "2         Economy  \n",
       "3             NaN  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two DataFrames and remove duplicates\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine_first.html\n",
    "full_df = verbose_spac_df.set_index('_id').combine_first(spac_df.set_index('_id')).reset_index()\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2320, 20)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our DataFrame to a CSV file so we can just load it in the future\n",
    "full_df.to_csv(\"data/nyt/nyt_spac.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df = pd.read_csv(\"data/nyt/nyt_spac.csv\")\n",
    "# full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'abstract', 'web_url', 'snippet', 'lead_paragraph',\n",
       "       'print_section', 'print_page', 'source', 'multimedia', 'headline',\n",
       "       'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name',\n",
       "       'byline', 'type_of_material', 'word_count', 'uri', 'subsection_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['pub_date'] = pd.to_datetime(full_df['pub_date']) # convert to datetime\n",
    "full_df['abstract'] = full_df['abstract'].astype(str) # convert to string\n",
    "full_df['lead_paragraph'] = full_df['lead_paragraph'].astype(str) # convert to string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting The Occurrences of Articles over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/4wc1x1s934q1t58trc5dtw0h0000gp/T/ipykernel_22655/371600974.py:2: FutureWarning:\n",
      "\n",
      "Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                          2320\n",
       "unique                         2212\n",
       "top       2000-06-14 05:00:00+00:00\n",
       "freq                              3\n",
       "first     1865-09-03 05:00:00+00:00\n",
       "last      2023-01-20 21:02:30+00:00\n",
       "Name: pub_date, dtype: object"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 5 number summary of the publication dates\n",
    "full_df['pub_date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      2320.000000\n",
       "mean       1660.197845\n",
       "std        4100.339873\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%         852.000000\n",
       "75%        1756.250000\n",
       "max      102439.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 5 number summary of the word counts\n",
    "full_df['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/4wc1x1s934q1t58trc5dtw0h0000gp/T/ipykernel_22655/2377877904.py:2: UserWarning:\n",
      "\n",
      "Converting to PeriodArray/Index representation will drop timezone information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a histogram of the publication dates, setting each month as a bin\n",
    "px.histogram(full_df['pub_date'], nbins=full_df['pub_date'].dt.to_period('M').unique().shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this graph, we see the majority of the articles start around 1930. Trim the data only include entries with publication dates >= 1930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df[full_df['pub_date'] > dt.datetime(1930, 1, 1).astimezone(tz=dt.timezone.utc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/4wc1x1s934q1t58trc5dtw0h0000gp/T/ipykernel_22655/3243197738.py:1: UserWarning:\n",
      "\n",
      "Converting to PeriodArray/Index representation will drop timezone information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = px.histogram(full_df, x='pub_date', nbins=full_df['pub_date'].dt.to_period('M').unique().shape[0])\n",
    "g.update_layout(\n",
    "    title = \"Number of NYT Articles with the keyword SPAC or Special Purpose Acquisition Company by Month\",\n",
    "    xaxis_title = \"Month\",\n",
    "    yaxis_title = \"Number of Articles\"\n",
    ")\n",
    "g.update_xaxes(\n",
    "    tickangle = 45,\n",
    "    tickformat = '%b %Y'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our hypothesis stated, there is a spike in NYT articles containing the keyword \"SPAC\" or \"Special Purpose Acquisition Company\" in 2020/2021."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship Between Time and Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the word counts and publication dates correlate?\n",
    "px.scatter(full_df, x='pub_date', y='word_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/work/opt/anaconda3/envs/python311/lib/python3.11/site-packages/pandas/core/arraylike.py:402: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a log scale for the y axis\n",
    "g = px.scatter(x=full_df['pub_date'], y=np.log(full_df['word_count']))\n",
    "g.update_layout(\n",
    "    title = \"Log of Word Count vs Publication Date\",\n",
    "    xaxis_title = \"Publication Date\",\n",
    "    yaxis_title = \"Log of Word Count\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this scatter plot, we can see their does not seem to be an apparent relationship between the article's publication date and the word count."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Section Names of Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the most common sections the articles appear in\n",
    "px.bar(full_df.value_counts('section_name')[full_df.value_counts('section_name') >= 10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Data Analysis\n",
    "\n",
    "## Machine Learning (Topic Modeling)\n",
    "\n",
    "Topic modeling is a type of statistical modeling for discovering the abstract topics that occur in a collection of documents. Essentially, it is a method for finding a group of words (i.e., a topic) from a collection of documents that best represents the information in the collection. It's a form of text mining - a way to identify patterns in a large collection of text data, which we often refer to as a \"corpus\".\n",
    "\n",
    "### Latent Dirichlet Allocation (LDA)\n",
    "Latent Dirichlet Allocation (LDA) is an example of a topic model and is used to classify text in a document to a particular topic. It builds a topic per document model and words per topic model, modeled as Dirichlet distributions.\n",
    "\n",
    "The LDA model discovers the different topics that the documents represent and how much of each topic is present in a document. In essence, it assumes that each document in a corpus is a combination of a finite number of topics, and each word in the document can be attributed to one of the document's topics.\n",
    "\n",
    "### Why Use LDA for Analyzing the New York Times Articles on Special Purpose Acquisition Companies (SPACs)?\n",
    "As we have a large number of articles from the New York Times relating to SPACs, it becomes nearly impossible to read through every article and understand the key themes or topics manually. That's where the LDA model becomes particularly useful.\n",
    "\n",
    "Using LDA for this task helps us automatically discover the main topics discussed in these articles, providing a high-level overview of the common themes. By applying the LDA model, we can find out which topics were most prevalent over time, helping us understand how the discussion around SPACs has evolved.\n",
    "\n",
    "It can also highlight the context in which SPACs are being discussed, such as in relation to financial regulations, market trends, or specific industries. This information can be crucial in providing a more structured and deep understanding of the news corpus.\n",
    "\n",
    "In conclusion, LDA is a powerful tool for analyzing large collections of text data, uncovering hidden thematic structures, and helping in the understanding of large-scale trends and patterns. By using LDA in conjunction with Python's Scikit-Learn library, we can effectively analyze and interpret our corpus of New York Times articles.\n",
    "\n",
    "### Resources\n",
    "\n",
    "* [Topic Modeling with LDA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)\n",
    "* [Latent Dirichlet Allocation (LDA)](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2290, 10322)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "\n",
    "# Combine the abstract and lead_paragraph columns into one column\n",
    "full_df['text'] = full_df['abstract'] + '\\n' + full_df['lead_paragraph']\n",
    "\n",
    "# Want to exclude \"New York City\" from the LDA model along with the default english words\n",
    "custom_stop_words = list(ENGLISH_STOP_WORDS)\n",
    "custom_stop_words.extend(['new', 'york', 'city'])\n",
    "\n",
    "# Transform the 'abstract' column into a document-term matrix\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words=custom_stop_words)\n",
    "dtm = vectorizer.fit_transform(full_df['text'])\n",
    "\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(random_state=42)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train LDA model\n",
    "# Note: You might want to tune the number of topics (n_components parameter)\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "lda.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = lda.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5  # Number of top words in each topic\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# For each document, get the top words in each of its top topics\n",
    "top_words_for_each_doc = []\n",
    "top_topic_for_each_doc = []\n",
    "top_topic_prob_for_each_doc = []\n",
    "\n",
    "for prob_dist in topic_results:\n",
    "    # Get the probability of the top topic for this document\n",
    "    top_topic_prob = np.sort(prob_dist)[-1]\n",
    "    top_topic_prob_for_each_doc.append(top_topic_prob)\n",
    "    # Get the top topic for this document\n",
    "    top_topic = np.argsort(prob_dist)[-1]\n",
    "    top_topic_for_each_doc.append(top_topic)\n",
    "    # Get the top words for this topic\n",
    "    top_words_for_topic = np.argsort(lda.components_[top_topic])[::-1][:top_words]\n",
    "    top_words_for_each_doc.append([feature_names[i] for i in top_words_for_topic])\n",
    "\n",
    "full_df['main_topic_index'] = top_topic_for_each_doc\n",
    "full_df['main_topic_prob'] = top_topic_prob_for_each_doc\n",
    "full_df['main_topic'] = top_words_for_each_doc\n",
    "full_df['main_topic_str'] = full_df['main_topic'].apply(lambda x: ', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1710, 25)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some of the entries have empty of not useful abstracts and lead paragraphs\n",
    "# Remove those entries\n",
    "clean_df = full_df[full_df['lead_paragraph'].notna()] # Remove rows where 'lead_paragraph' is NaN\n",
    "clean_df = clean_df[clean_df['lead_paragraph'].str.strip() != ''] # Remove rows where 'lead_paragraph' is whitespace or empty string\n",
    "clean_df = clean_df[clean_df['abstract'].str.split().str.len() >= 3]  # Keep rows where 'abstract' has at least three words\n",
    "\n",
    "clean_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: Federal efforts to prop up carriers saved jobs, but taxpayers likely paid big price.\n",
      "Lead Paragraph: Major U.S. airlines have received more than $50 billion in grants in multiple rounds of taxpayer-funded bailouts during the pandemic. As travel begins to rebound and the stock market cruises to record highs, Andrew asks in his latest column: Was the rescue worth it?\n",
      "Main Topics: ['united', 'states', 'president', 'washington', 'today']\n",
      "Main Topic Probability: 0.3034787855947011\n",
      "\n",
      "Abstract: THE future of Lake Compounce Amusement Park, which has been uncertain for the past several months, looks a bit brighter now that a group of investors has announced that it will renovate the park and reopen it in May 1986, in time for its 141st birthday.\n",
      "\n",
      " Lake Compounce, which straddles the towns of Bristol and Southington, is said to be the oldest continuously operating amusement park in the country and is the largest of Connecticut's three amusement parks, which include Lake Quassapaug in Middlebury and Ocean Beach Park in New London.\n",
      "\n",
      "Since it was founded in 1846 by Gad Norton, Lake Compounce has been owned and operated by four generations of the Norton family of Bristol. But J. Harwood Norton Jr., great- grandson of the park's founder and president of Norton Enterprises of Bristol, said the family recently decided to sell the park, for an undisclosed sum, because family members are spread out all over the country now and there is no longer ''the fine continuity and unanimity of purpose as in the old days,'' he said.\n",
      "\n",
      "The park was open only on weekends last summer, and will be open for only a few days this summer while it is being remodeled into a family entertainment center that recaptures the sights and sounds of the early 1900's, according to its new owners.\n",
      "Lead Paragraph: THE future of Lake Compounce Amusement Park, which has been uncertain for the past several months, looks a bit brighter now that a group of investors has announced that it will renovate the park and reopen it in May 1986, in time for its 141st birthday.\n",
      "Main Topics: ['company', 'said', 'steel', 'electric', 'motors']\n",
      "Main Topic Probability: 0.9916649863749986\n",
      "\n",
      "Abstract: A retired Army general and analyst has flourished at the intersection of network news and wartime commerce.\n",
      "Lead Paragraph: In the spring of 2007 a tiny military contractor with a slender track record went shopping for a precious Beltway commodity.\n",
      "Main Topics: ['company', 'said', 'steel', 'electric', 'motors']\n",
      "Main Topic Probability: 0.9624954824356176\n",
      "\n",
      "Abstract:   The Supreme Court, upholding the idea of community-based banking, ruled today that regional banking zones were valid under both Federal law and the Constitution. The vote was 8 to 0.   The Court upheld the so-called New England Compact, under which Massachusetts and Connecticut permit New England-based bank holding companies, but not those from New York or other states outside the region, to acquire local banks.   Similar regional banking zones are spreading quickly across the country, with 15 states now participating and others actively considering the step. The zones share the common purpose of strengthing regional banking while at the same time protecting local banks from acquisition by or direct competition from big banks in New York and other money centers.\n",
      "Lead Paragraph: The Supreme Court, upholding the idea of community-based banking, ruled today that regional banking zones were valid under both Federal law and the Constitution. The vote was 8 to 0.\n",
      "Main Topics: ['company', 'acquisition', 'deal', 'companies', 'said']\n",
      "Main Topic Probability: 0.7211320049659006\n",
      "\n",
      "Abstract: The following is a transcript of the Republican Presidential debate in Dearborn, Mich., as provided by the Federal News Service.\n",
      "Lead Paragraph: The following is a transcript of the Republican Presidential debate in Dearborn, Mich., as provided by the Federal News Service.\n",
      "Main Topics: ['united', 'states', 'president', 'washington', 'today']\n",
      "Main Topic Probability: 0.6931361787244948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a random sample of 5 articles and their main topic\n",
    "for abstract, lead_paragraph, main_topic_prob, main_topic in clean_df[['abstract', 'lead_paragraph', 'main_topic_prob', 'main_topic']].sample(n=5).values:\n",
    "    print(\"Abstract: %s\" % abstract)\n",
    "    print(\"Lead Paragraph: %s\" % lead_paragraph)\n",
    "    print(\"Main Topics: %s\" % main_topic)\n",
    "    print(\"Main Topic Probability: %s\" % main_topic_prob)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Avg. Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company, acquisition, deal, companies, said</td>\n",
       "      <td>467</td>\n",
       "      <td>0.705027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bank, president, trump, media, social</td>\n",
       "      <td>199</td>\n",
       "      <td>0.726280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public, year, million, company, saratoga</td>\n",
       "      <td>193</td>\n",
       "      <td>0.758899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>percent, company, said, shares, stake</td>\n",
       "      <td>173</td>\n",
       "      <td>0.797069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text, wall, street, says, state</td>\n",
       "      <td>143</td>\n",
       "      <td>0.758902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>company, times, government, american, cbs</td>\n",
       "      <td>129</td>\n",
       "      <td>0.773991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>united, states, president, washington, today</td>\n",
       "      <td>125</td>\n",
       "      <td>0.740687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>company, said, steel, electric, motors</td>\n",
       "      <td>118</td>\n",
       "      <td>0.754455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>com, designer, style, slide, times</td>\n",
       "      <td>104</td>\n",
       "      <td>0.746683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>street, 212, tickets, 30, tomorrow</td>\n",
       "      <td>59</td>\n",
       "      <td>0.575200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Topic  Count  Avg. Probability\n",
       "0   company, acquisition, deal, companies, said    467          0.705027\n",
       "1         bank, president, trump, media, social    199          0.726280\n",
       "2      public, year, million, company, saratoga    193          0.758899\n",
       "3         percent, company, said, shares, stake    173          0.797069\n",
       "4               text, wall, street, says, state    143          0.758902\n",
       "5     company, times, government, american, cbs    129          0.773991\n",
       "6  united, states, president, washington, today    125          0.740687\n",
       "7        company, said, steel, electric, motors    118          0.754455\n",
       "8            com, designer, style, slide, times    104          0.746683\n",
       "9            street, 212, tickets, 30, tomorrow     59          0.575200"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most common topics and their average probabilities\n",
    "count_topic_df = clean_df \\\n",
    "    .groupby('main_topic_str') \\\n",
    "    .count()[['_id']] \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns={'_id': 'Count', 'main_topic_str': 'Topic'}) \\\n",
    "    .sort_values('Count', ascending=False)\n",
    "\n",
    "avg_topic_prob_df = clean_df \\\n",
    "    .groupby('main_topic_str') \\\n",
    "    .mean(numeric_only=True)[['main_topic_prob']] \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns={'main_topic_prob': 'Avg. Probability', 'main_topic_str': 'Topic'}) \\\n",
    "\n",
    "count_topic_df = count_topic_df.merge(avg_topic_prob_df, on='Topic')\n",
    "\n",
    "count_topic_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the above table shows, extracted from the article abstract and leading paragraphs, the topic all the most popular topics are related to business terms like \"company,\" \"money,\" and \"stock.\" The highest ranking topic with 467 articles that best fit that topic has the words \"company, acquisition, deal, companies, said.\" These words strongly match the phrase special purpose acquisition company, giving good confidence to the quality of our data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP (Sentiment Analysis)\n",
    "\n",
    "\n",
    "### What is Natural Language Processing?\n",
    "Natural Language Processing (NLP) is a subfield of artificial intelligence and computational linguistics that focuses on the interaction between computers and humans through natural language. The goal of NLP is to enable computers to understand, interpret, and generate human language in a valuable way.\n",
    "\n",
    "NLP involves several tasks, including but not limited to:\n",
    "\n",
    "* Text Analysis: Understanding the structure of the language, including grammar and syntax.\n",
    "* Semantic Analysis: Understanding the meaning of the text.\n",
    "* Sentiment Analysis: Determining the sentiment or emotion expressed in the text.\n",
    "* Text Generation: Creating meaningful text based on certain inputs or requirements.\n",
    "\n",
    "### NLP in Our Project\n",
    "\n",
    "It's one thing to have a lot of articles published on a topic. It's another thing to know if there articles are positive or negative. While some say that all publicity is good publicity, we are interested in finding out more about public awareness and public opinion on SPACs. Whether these articles have positive or negative sentiment to them matters for this case.\n",
    "\n",
    "One of the columns of our NYT articles dataframe is `web_url` which contains the link to the published article on the New York Times website. In theory, we could request the HTML content of all these web pages, scrape the web page so we are only getting the text content, and then running NLP on the text for each article. In practice, this proves to be quite difficult.\n",
    "\n",
    "1. Our data frame has roughly 2,500 rows, meaning we'd have to scrape 2,500 websites. Making that many requests to the New York Times would likely cause a rate limit.\n",
    "2. The New York Times puts all its articles behind a paywall and does not load the article's content unless its reader logs in.\n",
    "3. Not all New York Times articles are guaranteed to put their article content in the same HTML tag\n",
    "\n",
    "### Resources\n",
    "\n",
    "* [What is Natural Language Processing?](https://cloud.google.com/learn/what-is-natural-language-processing#:~:text=Natural%20language%20processing%20(NLP)%20uses,media%20sentiment%20and%20customer%20conversations.)\n",
    "* [NLTK Docs](https://www.nltk.org/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.nytimes.com/2023/01/20/business/media/vice-puts-itself-up-for-sale.html'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_web_url = full_df.sort_values('pub_date', ascending=False).iloc[0]['web_url']\n",
    "test_web_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<html><head><title>nytimes.com</title><style>#cmsg{animation: A 1.5s;}@keyframes A{0%{opacity:0;}99%{opacity:0;}100%{opacity:1;}}</style></head><body style=\"margin:0\"><p id=\"cmsg\">Please enable JS and disable any ad blocker</p><script data-cfasync=\"false\">var dd={\\'rt\\':\\'c\\',\\'cid\\':\\'AHrlqAAAAAMAuDUOvjFeGvsAgQJZKA==\\',\\'hsh\\':\\'499AE34129FA4E4FABC31582C3075D\\',\\'t\\':\\'bv\\',\\'s\\':17439,\\'e\\':\\'0e01e9bec9400f0403bbe22987c064a63aebde047ed34ebba3b3ea7c9d510005\\',\\'host\\':\\'geo.captcha-delivery.com\\'}</script><script data-cfasync=\"false\" src=\"https://ct.captcha-delivery.com/c.js\"></script></body></html>\\n'"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(test_web_url)\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please enable JS and disable any ad blocker']"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "soup.find_all(string=\"Please enable JS and disable any ad blocker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The new york times publishes text content in the <article> tag\n",
    "soup.find(\"article\") is None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can't easily make HTTP requests to scrape NYT article text content, we should look to our DataFrame for columns which we can do NLP on. We'll use the text column that we created for the Topic Modeling which is the combination of the abstract and lead paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/work/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    # Get the sentiment scores\n",
    "    sentiment_scores = sid.polarity_scores(text)\n",
    "    # Return the compound score\n",
    "    return sentiment_scores['compound']\n",
    "\n",
    "clean_df['sentiment'] = full_df['text'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = px.histogram(\n",
    "    clean_df, \n",
    "    x='sentiment', \n",
    "    color_discrete_sequence=['lightblue'], \n",
    "    opacity=0.8,\n",
    "    title='Sentiment Score Distribution of SPAC NYT Articles',\n",
    "    labels={'sentiment':'Sentiment Score', 'count': 'Proportion'},\n",
    ")\n",
    "fig.update_layout(bargap=0.05)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the histogram of sentiment scores on our cleaned dataset, the distribution of the sentiment scores appears to be bimodal with peaks at 0 and 0.9. From the information gathered about the articles' abstract and leading paragraph (*note this is a limitation on the accuracy of our sentiment analysis*) a large amount of sentiments are either neutral or very positive. This result is unexpected as I'd imagine that the sentiment on articles written about SPACs would be closer to neutral or negative.\n",
    "\n",
    "There are a few possible explanations for this.\n",
    "\n",
    "1. The training data of the vader lexicon NLP model trained on data that looks significantly different (and more negative) from from the NYT article data we are feeding it. \n",
    "2. Related, the NYT write their articles in such a way that sentiment of their abstracts and leading paragraphs are either in a neutral or positive tone. This would explain the peak around 0.0 as most journalist try to write in an unbiased tone unless they are writing op-eds.\n",
    "3. The NYT writers hold favorable views of SPACs and are writing positive articles on them.\n",
    "\n",
    "Of the explanations, I believe that explanation #1 is most likely. To better tune the model, we could train it on other abstracts and leading paragraph from a random, representative group of NYT articles. This however is outside of the scope of the project but would be interesting to explore."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Conclusion and Insight\n",
    "\n",
    "Through this project, we learned:\n",
    "* What a SPAC (special purpose acquisition company) is and a notable researcher in the field.\n",
    "* How to use the NYT API\n",
    "* New York Times articles with the keyword \"special purpose acquisition company\" or \"SPAC\" saw a huge spike in 2020/2021\n",
    "* What a LDA (Latent Dirichlet Allocation) is and how we can classify documents using it\n",
    "* The most common topics for NYT articles with the keyword SPAC are all heavily business and finace related.\n",
    "* The high amount positive sentiment in New York Times articles with the keyword SPAC\n",
    "\n",
    "<iframe src=\"https://giphy.com/embed/lD76yTC5zxZPG\" width=\"480\" height=\"352\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/the-end-thats-all-folks-lD76yTC5zxZPG\">via GIPHY</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
